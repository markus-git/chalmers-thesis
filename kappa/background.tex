%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%   .--~*teu.
%  dF     988Nx
% d888b   `8888>
% ?8888>  98888F
%  "**"  x88888~
%       d8888*`
%     z8**"`   :
%   :?.....  ..F
%  <""888888888~
%  8:  "888888*
%  ""    "**"`
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[../paper.tex]{subfiles}
\begin{document}

\chapter{Background}
\label{background}

Today we see embedded systems consisting of everything from general purpose processors (GPPs) to application specific integrated circuits (ASICs). GPPs and ASICs represent two extremes of available architectures, and somewhere in the middle, field programmable gate arrays (FPGAs) can be found. FPGAs provide the best of both worlds: they are close to hardware and can be reprogrammed~\cite{bacon2013}. Modern FPGAs also contain various components and co-processors which may be specialized to handle a certain task well, and they have a good performance per Watt ration. These properties have made them increasingly popular to use in high-performance, computationally intensive systems~\cite{mcmillan2014}. 

While a modern FPGA shows great promise as a prototypical system for heterogeneous computing, its adoption has been slowed down by the fact that it is difficult to program. The logic blocks of an FPGA are usually programmed in a hardware description language, while its co-processors are programmed in some low-level dialect of C or even assembler. Low-level languages are typically used for embedded systems since they give a designer fine control over the system's capabilities. Such fine control does however come at a cost---a programmer cannot abstract away from the specific system architecture, but must keep the implementation on a low level during the entire design process. Other issues, related to functionality and modularity, come as consequences of the lack of abstraction.

In his paper ``Why functional programming matters''~\cite{hughes1989}, Hughes argues that many of the problems with low-level languages can be addressed by making use of functional programming. In particular, the glue code that functional programming languages offer (through higher-order functions and lazy evaluation) enables building useful combinators. The benefits of a functional programming language are not limited to describing software, as Sheeran shows in her paper ``Hardware Design and Functional Programming: a Perfect Match''~\cite{sheeran2005}. Sheeran exemplifies how a functional language can make it easy to explore and analyze hardware designs in a way that would have been difficult, if not impossible, in traditional hardware description languages.

\section{Functional Programming}
\label{functional}

Functional programming is based around the application of a function to its arguments. In this programming style, a program is written as a function that accepts input and delivers its result. That function itself is defined in terms of smaller functions, which in turn are defined using smaller functions still and, in the end, a function consists of nothing but language primitives.

An important distinction between the functions in a functional programming language and functions in, say an imperative language like C, is that these always return the same value for the same arguments. It is said that functional programs have no side effects, and this makes it possible for functions to be safely evaluated in parallel, as long as their data dependencies are satisfied.

A function that accepts other functions as arguments is often referred to as a higher-order function, or a combinator, and provides a useful piece of glue code that lets a programmer build complex functions from smaller ones. In Haskell, a number of such higher-order functions are provided by its standard libraries. One of these is \codei{map}, which can be defined as follows:

\begin{code}
map :: (a -> b) -> [a] -> [b]
map f []     = []
map f (x:xs) = f x : map f xs
\end{code}

The first line specifies the type of \codei{map}, because in Haskell, every function is assigned a static type in an effort to attain safer programs---if a function is applied to a value that does not match its type, the compiler will reject the function and instead point out the type mismatch. In the case of \codei{map}, its type is a function that takes two arguments: a function \codei{f :: a -> b} and a list \codei{xs :: [a]}, and returns an element of type \codei{b}. The second line of \codei{map} specifies that it, when given an empty list as denoted by \codei{[]}, returns another empty list. The third line states that for non-empty lists, \codei{f} should be applied to the list's head and a recursive call should be made with the tail of the list as an argument.

The usefulness of higher-order functions like \codei{map} comes from their ability to encode common patterns: \codei{map} works for all functions and lists that fit its type signature. Functions like \codei{map} are often referred to as combinators---a style of organizing libraries around a few primitive values and functions for combining them. These combinators allow for complex structures to be built from a small set of pre-verified functions. For example, the dot-product from section~\ref{intro} is composed by two combinators: \codei{zipWith}, a generic way of joining two vectors, and \codei{sum}:

\begin{code}
zipWith :: (a -> b -> c) -> Vec a -> Vec b -> Vec c
zipWith f a b = fmap (uncurry f) $ zip a b

sum :: Vec Int -> Int
sum = fold (+) 0
\end{code}

\noindent \codei{fmap} here is similar to the above \codei{map} but works for vectors instead of lists, \codei{zip} joins two vectors into a single vector of pairs, and \codei{fold} reduces a vector into a scalar value using addition and starting at zero.

The other piece of glue code that functional programming languages provides is often referred to as function composition, and enables programs to be glued together. Say that \codei{f} and \codei{g} are two programs, then \codei{g} composed with \codei{f} is written \codei{g <> f} and is a program that, when applied to its input \codei{x}, computes \codei{g (f x)}. In Haskell, we can define function composition as:

\begin{code}
(.) :: (b -> c) -> (a -> b) -> a -> c
(.) g f x = g (f x)
\end{code}

\noindent where parentheses around the dot imply that function composition is an infix function.

While the size of the intermediate result of \codei{f} could potentially spoil any usefulness of the composition, functional programming solves this by only evaluating \codei{f} as much as is needed by \codei{g}. This property is referred to as lazy evaluation and lets us fuse functions without creating any unnecessary, intermediate values. Its benefits extend to embedded types as well, and guarantees fusion of vectors.

This section has given a brief overview of functional programming in Haskell and its beneficial properties for embedded languages. So far, the distinction between regular and embedded Haskell have yet been made. The following section introduces the concept of domain specific languages, and explains what it entails to be an embedded in Haskell. 

\section{Domain Specific Languages}
\label{domain}

A domain specific language (DSL) is a special-purpose language, tailored to a certain problem and capturing the concepts and operations in its domain. For instance, a hardware designer might write in VHDL, while a web-designer that wants to create an interactive web-page would use JavaScript. DSLs come in two fundamentally different forms: external and internal, where VHDL and JavaScript are both examples of the former.

Internal DSLs are embedded in a host language, and are often referred to as embedded domain specific languages (EDSLs). Haskell, with its static type system, flexible overloading and lazy semantics, has come to host a range of EDSLs~\cite{elliott2003}. For instance, popular libraries for parsing, pretty printing, hardware design, and testing have all been embedded in Haskell~\cite{leijen2002, hughes1995, bjesse1998}.

EDSLs in Haskell are further divided into one of two kinds: shallow or deep. Conceptually, a shallow embedding captures the semantics of the data in a domain, whereas a deep embedding captures the semantics of the operations in a domain. Both kinds of embeddings have their own benefits and drawbacks. To illustrate the differences between shallow and deep embeddings, a small example domain can be implemented:

\begin{code}
type Exp = Int

const :: Int -> Exp
const a = a

times :: Exp -> Exp -> Exp
times a b = a * b
\end{code}

\noindent where \codei{Exp} is a short-hand for expressions and is defined as a type synonym for integers, thus an example of a shallow EDSL. Two functions are also provided: \codei{const} to lift integer literals, and \codei{times} to multiply expressions.

Two benefits of a shallowly embedded language like \codei{Exp} are that it is easy to add new functions and that evaluation is straightforward---the a value of type \codei{Exp} is the result of some expression. On the other hand, it is difficult to compile shallow types as there is no representation of the expressing that built its value. It is easier to compile an embedded language if its functions instead return an intermediate representation of their result, which sits between Haskell and the compiled code~\cite{elliott2003}. This technique is known as deep embedding, and \codei{Exp} can be reimplemented using it:

\begin{code}
data Exp = Const Int | Times Exp Exp

const :: Int -> Exp
const a = Const a

times :: Exp -> Exp -> Exp
times a b = Times a b
\end{code}

\noindent where \codei{Exp} is now a datatype that lists all supported expressions, which \codei{const} and \codei{times} use to construct their results.

As values in a deeply embedded language like \codei{Exp} are representations of the expressions that built it, rather than their result, it is possible to interpret them and, for example, define a function that evalutes them into integers:

\begin{code}
eval :: Exp -> Int
eval (Const a)   = a
eval (Times a b) = (eval a) * (eval b)
\end{code}

\noindent The ability to interpret values come at the cost of making it harder to add new functions over \codei{Exp} without first extending its datatype.

While the implementation of shallow and deep embedding are usually at odds, there has been work done in order to combine their benefits~\cite{svenningsson2012}. The co-design language does make use of such a combination of deep and shallow embeddings: its core datatype is implemented using a deep embedding and user facing libraries use shallow embeddings built on top of the core. This mixture of embeddings ensures that the core is easy to interpret while simultaneously allowing user-facing libraries to provide a nice and extensible syntax.

At this point, this section and the previous one have given a brief overview of functional programming and domain specific languages, showcasing Haskell and the benefits its functional style provides for embedded languages. The next section introduces the co-design language through a few examples and highlights these benefits.

\section{Embedded Programming in Haskell}
\label{embedded}

Programming in a functional language like Haskell is quite different from the imperative style of programming used in a language like C. As an example of these differences, consider a finite impulse response (FIR) filter, one of the two primary types of digital filters used in digital signal processing applications~\cite{oppenheim1989}. The mathematical definition of a FIR filter of rank $N$ is as follows:

\begin{equation}
y_{n} = b_{0} x_{n} + b_{1} x_{n-1} + \cdots + b_{N} x_{n-N} = \sum_{i=0}^{N} b_{i} x_{n-i}
\end{equation}
\vspace{1mm}

\noindent where $x$ and $y$ are the input and output signals, respectively, and $b_i$ is the value of the impulse response at time instant $i$. The inputs $x_{n-i}$ are sometimes referred to as ``taps'', since they \textit{tap into} the input signal at various time instants. 

The FIR filter can be implemented in C as:

\begin{code}
void fir(int N, int L, double *b, double *x, double *y) {
 int j, k;
 double tap[256];
 for(j=0; j<N; j++) tap[j] = 0.0;
 for(j=0; j<L; j++) {
  for(k=N; k>1; k--) tap[k-1] = tap[k-2];
  tap[0] = x[j];
  y[j] = 0.0;
  for(k=0; k<N; k++) y[j] += b[k] * tap[k]; (#\label{line:dot}#)
 }
}
\end{code}

\noindent where $N$ is the filter rank, $L$ is the size of the input, and $b$, $x$, and $y$ are pointers to the filter's coefficients, input, and output, respectively.

At first glance, the C code seems to be a good representation of the FIR filter, but there are a few problems with its implementation. For example, the for-loop on line~\ref{line:dot} calculates a dot-product of the arrays $b$ and $tap$ inline. It is possible to extract the product:

\begin{code}
double dot(int N, double *xs, double *ys) {
  double sum = 0;
  for (int i=0; i<N; i++) sum += xs[i] * ys[i];
  return sum;
}
\end{code}

\noindent but it is still specialized to values of type $double$, it assumes that $b$ and $tap$ both have at least $N$ elements, and it is not compositional in the sense that it cannot be merged with the producers of \codei{xs} or \codei{ys} without looking at their implementation first.

The same dot product can be implemented in the co-design language, using a similar, but not idiomatic, imperative style:

\begin{code}
dotSeq :: Arr Float -> Arr Float -> Program (Exp Float)
dotSeq x y = do
  sum <- initRef 0
  for 0 (min (length x) (length y) $ \ix -> do
    a <- getArr x ix
    b <- getArr y ix
    modifyRef sum $ \s -> s + a * b
  getRef sum
\end{code}

\noindent Note that \codei{dotSeq} returns a program, which in turn returns a floating point expression. Programs are a type of \textit{monad}, that is, they are a kind of composable computation description; the functions that manages references and arrays are all monadic, and they are sequenced to look like an imperative program by using Haskell's \codei{do} notation.

\codei{dotSeq} is not without its own faults, as it is limited to floating point expressions and indices are given manually. The first of these issues can be resolved by Haskell's type class for basic numerical operations, called \codei{Num}. With it, \codei{dotSeq} can be made polymorphic in the kind of values it accepts but still restricted to numerical values that support the required operations:

\begin{code}
dotSeq :: Num a => Arr a -> Arr a -> Program (Exp a)
\end{code}

\noindent In order to address the manual indexing of \codei{dotSeq}, the idiomatic approach would be to reimplement the dot product using the vector language instead:

\begin{code}
dotVec :: Num a => Vec a -> Vec a -> Exp a
dotVec xs ys = sum (zipWith (*) xs ys)
\end{code}

A dot product based on vectors is not only closer to its mathematical specification, but also sturdier in the sense that it is harder for users to make an error: indices and lengths are now hidden by verified vector functions. Furthermore, Haskell's lazy evaluation ensures that \codei{dotVec} can be merged freely with the producers of \codei{xs} and \codei{ys}.

Compiling \codei{dotVec} to C with two small example inputs and printing its result to standard output produces the following code (with imports omitted for brevity):

\begin{code}
int main() {
  uint16_t _a0[] = {1, 2, 3, 4}, *a0 = _a0;
  uint16_t _a1[] = {4, 3, 2, 1}, *a1 = _a1;
  uint16_t state2 = 0;
  uint32_t v3;
  for (v3 = 0; v3 < 4; v3++)
    state2 = a0[v3] * a1[v3] + state2;
  fprintf(stdout, "result: %d\n", state2);
  return 0;
}
\end{code}

The vector language excels at describing array transformations, but it has some difficulty in describing the kind of recurrence equation that makes up a FIR filter. Nevertheless, a few such recurrence equations are provided by the vector library, one of which is the \codei{recurrenceI} function that can be used to implement the filter:

\begin{code}
firVec :: Num a => Vec a -> Vec a -> Program (Arr a)
firVec cs v = recurrenceI (replicate (length cs) 0) v $ \i -> dotVec cs i
\end{code}

\noindent The recurrence function takes an initial buffer to store old inputs in, a vector to iterate over, and a step function that produces one output at a time given these two inputs. Compiling \codei{firVec} to C can yield the following code, where imports and code unrelated to the filter have been omitted:

\begin{code}
int main() {    
  r5 = 0;
  for (v6 = 0; v6 <= 3; v6++) {
    a3[r5] = a1[v6];
    r5 = (r5 + 1) % 4;
    state7 = 0;
    for (v8 = 0; v8 < 4; v8++)
      state7 = a0[v8] * a3[(4 + r5 - v8 - 1) % 4] + state7;
    a2[v6] = state7;
  }
}
\end{code}

\noindent where \codei{a0} contains the coefficients, \codei{a1} the input array, and \codei{a3} is input buffer. Note that, since all inputs are present at once, it is possible to rewrite the filter and do without the queue for vectors for all but the first initial segments of the input:

\begin{code}
firQ :: Num a => Vec a -> Vec a -> Vec a
firQ coeff = map (dotVec coeff . reverse) . tail . inits
\end{code}

% \begin{code}
% int main() {
%   for (v3 = 0; v3 <= 3; v3++) {
%     if (4 <= v3 + 1) { b5 = 4; } else { b5 = v3 + 1; }
%     if (4 <= b5) { b4 = 4; }
%     else {
%       if (4 <= v3 + 1) { b6 = 4; } else { b6 = v3 + 1; }
%       b4 = b6;
%     }
%     state7 = 0;
%     for (v8 = 0; v8 < b4; v8++) {
%       if (4 <= v3 + 1) { b9 = 4; } else { b9 = v3 + 1; }
%       state7 = a0[v8] * a1[b9 - v8 - 1] + state7;
%     }
%     a2[v3] = state7;
%   }
% }
% \end{code}

Both \codei{firQ} and \codei{firVec} showed that an implementation of the FIR filter based on vectors is certainly possible, but they required that either the filter was rewritten to fit the vector library, or that a helper function for recurrence equations was available. Another approach is to instead use the signal processing language. Signals are possible infinite sequences of values, and introduce a notion of time: signals can be delayed to hold its input for some specified period. The FIR filter can be implemented with signals as follows:

\begin{code}
firSig :: Num a => [Exp a] -> Sig a -> Sig a
firSig coeffs = sums . muls coeffs . dels 0
\end{code}

\noindent where \codei{sums}, \codei{muls}, and \codei{dels} implement the three main components of the filter, that is, a summation, a multiplication with coefficients, and a number of successive delays access earlier inputs.

\begin{code}
sums :: Num a => [Sig a] -> Sig a
sums as = foldr1 (+) as

muls :: Num a => [Exp a] -> [Sig a] -> [Sig a]
muls as bs = zipWith (*) (map constant as) bs

dels :: Exp a -> Sig a -> [Sig a]
dels e as = iterate (delay e) as
\end{code}

\noindent \codei{constant} and \codei{delay} are signal functions that introduce a constant signal and a unit delay, respectively.

% We should note that \codei{foldr1}, \codei{zipWith}, \codei{map} and \codei{iterate} are the standard Haskell functions for lists, as opposed to signal functions. Addition and multiplication are lifted to operate element-wise over signals. \codei{constant} and \codei{delay} are proper signal functions and introduce a constant signal and a unit delay, respectively.

From a hardware perspective, \codei{firSig} is arguably closer to the FIR filter's mathematical specification than \codei{firVec}: the input signal is iteratively delayed to form the filter's taps, each tap is then multiplied with a coefficient, after which the taps are summed to form the filters output. Compiling \codei{firSig} to VHDL produces the following hardware design:

% TODO: Might be an error in the code, as both processes trigger on the clock.
\begin{code}
ENTITY comp0 IS
  PORT (in0 : IN unsigned (7 DOWNTO 0);
        out1 : OUT unsigned (7 DOWNTO 0);
        clk : IN std_logic;
        rst : IN std_logic) ;
END ENTITY comp0 ;
ARCHITECTURE behav OF comp0 IS
  SIGNAL state2 : unsigned (7 DOWNTO 0) ;
  SIGNAL state2_d : unsigned (7 DOWNTO 0) := "00000000" ;
BEGIN
  l8 :
    PROCESS (in0) IS
      VARIABLE v3, v4, v5, v6, v7 : unsigned (7 DOWNTO 0) ; 
    BEGIN
      v3 := "00000001" ;
      v4 := "00000010" ;
      v5 := resize (v3 * ins0, 8) ;
      v6 := resize (v4 * state2_d, 8) ;
      v7 := resize (v5 + v6, 8) ;
      state2 <== in0 ;
      out1 <== v7 ;
    END PROCESS l8 ;
  l9 :
    PROCESS (clk) IS
    BEGIN
      IF rising_edge (clk) THEN
        state2_d <== state2 ;
      END IF ;
    END PROCESS l9 ;
END ARCHITECTURE behav ;
\end{code}

\section{Summary}

Section~\ref{intro} gave an introduction to heterogeneous embedded systems as a interesting development towards energy efficient computing. These systems are not without challenges, as the presence of multiple processing elements raises all of the issues involved with homogeneous systems in addition to the issues of heterogeneity in the system. A modern FPGA was presented as a prototypical heterogeneous system of note.

Functional languages were proposed in section~\ref{background} as a way to address issues typically found in embedded system design, in particular the modularity issues that come from the low-level languages they are usually programmed with. Section~\ref{functional} gave a brief overview of functional programming and section~\ref{domain} went on to demonstrate techniques for embedded languages in Haskell. Finally, section~\ref{embedded} showcased the co-design language, the current attempt at bringing the benefits of functional programming languages to the domain of embedded heterogeneous systems.

The remainder of this thesis covers the co-design, vector, and signal processing languages in detail and highlights the techniques they are built on. In particular, the following contributions are made:

\begin{itemize}
\item We present a language for hardware software co-design that is embedded in Haskell and designed with modern FPGA programming in mind, able to generate both C and VHDL for the FPGAs various processing elements, including the necessary glue code for connections between elements. Also, the language is extensible to support any differences in instruction sets between elements.

\item We present two extensions to the hardware software co-design language, one for vector computations and another for signal processing. The vector language supplements an array type with vector types and combinators that support fusion, and the signal processing language adds support for synchronous data-flow to an expression type. Both extensions are intended to be used with the co-design language, but abstract over their underlying types and can be used with other embedded languages as well.

\item We present the techniques used to implement a language like the co-design language, that is based on a monadic representation of imperative programs. The model is loosely coupled to its underlying statement, expression, and predicate types, enabling each type to be defined separately. Compilation of programs is defined as a typed translation between progressively smaller languages, which not only safeguards against common errors in untyped translations, but also provides control over the generated code.

% \item We present a code generation scheme for programs by a series of translations between progressively smaller languages, where each step is typed in order to safeguard against common errors found in untyped translations. This scheme allows for languages to provide users with feature-rich expressions, while still having fine control over the generated source code.
\end{itemize}

\end{document}

%%  LocalWords:  DSLs EDSLs
