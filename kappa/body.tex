%!TEX root = ../main.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%       oe    
%     .@88    
% ==*88888    
%    88888    
%    88888    
%    88888    
%    88888    
%    88888    
%    88888    
%    88888    
% '**%%%%%%** 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}

Over the last few years, the amount of traffic going back and forth between devices in the global communications infrastructure has been increasing at a rapid pace. As the steady growth of mobile users and internet of things devices continues~\cite{ericsson2016}, the amount of mobile traffic is projected to become even greater. In fact, global internet traffic is estimated to grow at an average rate of twenty two percent annually, reaching approximately two hundred and fifty million terabytes per month by the end of 2021~\cite{cisco2016}. For the communication infrastructure, the consequence of such a rapid growth rate has been a sharp increase in the demand for computational power on systems that already run under tight latency constraints and with limited memory~\cite{persson2014}, which means computations have to be efficient.

As important as it is to increase the computational power of embedded systems used in communication, limiting their power consumption presents an equally important issue in their architectural design~\cite{mudge2001}. The trend of trading power for performance cannot continue indefinitely: the house hold processors of today typically have a power density of 70W and upwards, which is seven times that of a typical hot plate. Containing the growth in power requires architectural improvements, with specialized computing for specialized tasks. Heterogeneous computing represents an interesting development towards the goal of energy efficient computing, and refers to systems that use more than one kind of processing units. These heterogeneous systems gain their performance and energy efficiency not just by combining several processors, but rather by incorporating different kinds of co-processors that provide specialized processing capabilities to handle a particular task.

Heterogeneous computing present new challenges in software design that are not found in the development for typical homogeneous systems~\cite{kunzman2011}. The multiple processing units present in a heterogeneous system raises all of the issues associated with homogeneous parallel systems, while the heterogeneity in the system gives rise to new issues due to  dissimilarity in system development and capability. The efficiency and computational power of heterogeneous systems thus comes at a cost of increased programming burden in terms of code complexity and portability, as hardware specific code is interleaved with application code to handle any communication between co-processors. Furthermore, the structure of application code typically vary between co-processors and any code written for one therefore requires modification when given a new target. In fact, despite all the advantages heterogeneous systems offer, their use so far has been mostly restricted to hardware programmers.

A substantial amount of research has gone into addressing the challenges of programming for embedded heterogeneous systems, opening them up for programmers without a background in hardware or embedded system design. However, hardware description languages, such as VHDL and Verilog, are still the most commonly used tools, together with C for specific co-processors. These hardware description languages have revolutionized hardware design but suffer from a lack of expressiveness and standardization -- there is a mismatch between description and synthesized hardware. Designers have therefore looked for alternative solutions, where one of the more well-known approaches is synthesis of high-level languages like C~\cite{graphics2008, ghenassia2005}. Compiling high-level languages to a hardware description has a great appeal but finding a translation between the two has however proven to be difficult; sequential programs are often a bad fit for the parallelism inherent to most hardware architectures.

Another group of languages whom I believe have shown success in describing hardware designs are functional languages~\cite{sheeran2005}. Higher-order functional languages in particular, where hardware descriptions are first-class objects, offer a particularly useful abstraction mechanism~\cite{baaij2010, bjesse1998, gill2010}. Another beneficial attribute of these languages is their purity, which enables reasoning about function (de-)composition. Functional languages are however rarely considered for embedded system development, as its difficult to give performance guarantees and resource bounds for its programs.

This thesis presents the first steps towards a functional programming language in which the entire design process of heterogeneous systems can be expressed. I do however intend to go further than solely describing hardware; some components are better described using sequential algorithms directly, rather than having one generated from a hardware description. I also intend to support the necessary design exploration to decide where the boundary between hardware and software should be drawn. 

This thesis consists of two parts. Part I is a general introduction to the field and puts the appended papers into context. Part II contains the appended papers.

% Limit to FPGAs.

\section{Background}

High demands for efficiency under resource constraints have greatly influenced the development of embedded systems used in communications infrastructure, both in terms of programming practice and architecture. Today, we see embedded systems consisting of everything between general purpose processors (GPPs) and application specific integrated circuits (ASICs). GPPs are highly programmable systems but often inefficient in terms of power consumption and performance. In contrast, ASICs implement a fixed function and can therefore provide good power and performance characteristics, but any changes to its functionality requires a new circuit to be designed. 

Processors and ASICs represent two extremes of available architectures, but fortunately there exists several other architectures in between. Field programmable gate arrays (FPGAs) are one such kind, and provides the best of both worlds: they are close to hardware and can be reprogrammed~\cite{bacon2013}. FPGAs typically consists of a large array of configurable logic blocks, connected by programmable interconnects. However, a modern FPGA also contain various discrete components and co-processors, which together with their good performance per Watt ratio, have seen them increasingly used in high-performance, computationally intensive systems.~\cite{mcmillan2014}.

% Customarily, any digital signal processing applications used in these embedded systems have been written in C or assembler, while hardware description languages like VHDL or Verilog are used for 

% Today, digital signal processing software for embedded systems is typically written in a low level dialect of C. This choice of language is primarily driven by the desire to access the full potential of a processor or its memory system. However, low level languages also forces its developers to focus on low level implementation details rather than the high level specification of the algorithm they are implementing.

% There has been a number of other approaches to hardware description using functional languages, most of which are focused on describing hardware through structural descriptions rather than sequential algorithms. Sheeran pioneered this approach with $\mu$FP~\cite{sheeran1984mufp}, which utilizes a set of functional combinators to support the composition of larger descriptions from existing ones. Various languages from the Lava family~\cite{bjesse1998lava, gill2010introducing} of languages have since built upon these ideas. None has however, to the extent of my knowledge, ventured into the design of heterogeneous architectures, like that of a modern FPGA. The benefits of figuring out how to programme such system is however in no way limited to FPGAs, as most future processors are likely going to be heterogeneous in exactly the same way~\cite{sheeran2015icfp}.

\section{Functional programming}

\lipsum[2]

\section{Domain Specific Languages}

\lipsum[3]

\section{Domain Specific Embedded Languages}

\lipsum[4]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%   .--~*teu.
%  dF     988Nx
% d888b   `8888>
% ?8888>  98888F
%  "**"  x88888~
%       d8888*`
%     z8**"`   :
%   :?.....  ..F
%  <""888888888~
%  8:  "888888*
%  ""    "**"`
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Co-Design}

\lipsum[5]

\section{Section about Expression}

\lipsum[1]

\begin{code}
square :: SExp Int32 -> SExp Int32
square a = a * a
\end{code}

\lipsum[1]

\begin{stub}
square :: HExp Int32 -> HExp Int32
square a = a * a
\end{stub}

\lipsum[1]

\begin{stub}
square :: (Multiplicative exp, Type' exp a, Num a) => exp a -> exp a
square a = a * a
\end{stub}

\lipsum[1]

\begin{code}
type Point a = (a, a)

pair :: (Expr exp, Type' exp a, Num a) => Point (exp a) -> Point (exp a) -> exp a
pair (a, b) (u, v) = (a + b) * (u + v)
\end{code}

\lipsum[1]

\begin{code}
dotProd :: (Expr exp, Type' exp a, Num a) => Pull exp a -> Pull exp a -> exp a
dotProd xs ys = forLoop n 0 $ \i s -> s + xs!i * ys!i
  where
    n = min (length xs) (length ys)
\end{code}

\lipsum[1]

\begin{stub}
forLoop :: Syntax exp st => exp Length -> st -> (exp Index -> st -> st) -> st
\end{stub}

\lipsum[1]

\begin{code}
zipWith :: Expr exp => (a -> b -> c) -> Pull exp a -> Pull exp b -> Pull exp c
zipWith f xs ys = fmap (uncurry f) (zip xs ys)

sum :: (Expr exp, Type' exp a, Num a) => Pull exp a -> exp a
sum = fold (+) 0
\end{code}

\lipsum[1]

\begin{code}
scProd :: (Expr exp, Type' exp a, Num a) => Pull exp a -> Pull exp a -> exp a
scProd a b = sum (zipWith (*) a b)
\end{code}

\section{Section about Programs}

\lipsum[1]

\begin{code}
hello :: Software ()
hello = printf "Hello world!\n"
\end{code}

\lipsum[2]

\begin{code}
hello :: Software ()
hello = printf "Hello world!\n"
\end{code}

\lipsum[3]

\begin{code}
reverse :: SArr Int32 -> Software ()
reverse arr =
  do for 0 (len `div` 2) $ \ix ->
       do aix <- getArr arr ix
          ajx <- getArr arr (len - ix)
          setArr arr ix         ajx
          setArr arr (len - ix) aix
  where
    len = length arr
\end{code}

\lipsum[4]

\begin{stub}
reverse :: HArr Int32 -> Hardware ()
\end{stub}

\lipsum[5]

\begin{stub}
reverse :: (Arrays m, Expr (Exp m), Type' (Exp m) Int32) =>
  Arr m (Exp m Int32) -> m ()
\end{stub}

\lipsum[6]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%   .x~~"*Weu.
%  d8Nu.  9888c
%  88888  98888
%  "***"  9888%
%       ..@8*"
%    ````"8Weu
%   ..    ?8888L
% :@88N   '8888N
% *8888~  '8888F
% '*8"`   9888%
%   `~===*%"`
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Concluding Remarks}
\label{ch:conc}

\lipsum
