%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%   .x~~"*Weu.
%  d8Nu.  9888c
%  88888  98888
%  "***"  9888%
%       ..@8*"
%    ````"8Weu
%   ..    ?8888L
% :@88N   '8888N
% *8888~  '8888F
% '*8"`   9888%
%   `~===*%"`
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[../main.tex]{subfiles}
\begin{document}

\chapter{Co-Design}
\label{codesign}

In section~\ref{embedded} we introduced a simplified version of our co-design, vector and signal languages to illustrate embedded programming in Haskell. We then went on to implement two versions of a FIR filter, one with vectors and one with signals, and showed their compiled C code. For the kind of heterogeneous computing that our co-design library aims to describe it is however not enough to only generate C code; heterogeneous system typically see hardware code interleaved with software code, even components described by the same language can differ by what intrinsic operations they support.

% C is perhaps the most commonly used language for writing software in embedded systems and is as such used by the co-design library as well. For hardware descriptions we use the VHDL language, purely based on the fact it is the hardware description language we are most comfortable with.

Starting with a single Haskell program, our co-design library is designed with three main tasks in mind: generate C code for the software parts, VHDL for the hardware parts, and to generate a combination of software and hardware for the transmission of data between components. Furthermore, the software and hardware programs are both extensible in the sense that they support the addition of new operations to account for differences between components.

\section{Hardware Software Programs}
\label{program}

While the C and VHDL languages different in that one describes software code and the other hardware designs, both languages exhibit an imperative style of programming. As a consequence, our co-design language is built on a deep embedding of monads, as a representation of imperative programs. Monads can be thought of as composable descriptions of computations, that is, they provide a means to connect smaller programs into a single, larger program.

The general idea behind a monadic embedding is that one can view an imperative program as a sequence of instructions to be executed on some machine---which looks similar to programs written in a stateful monad using Haskell's do-syntax. In fact, a stateful program composed with monadic operations can be directly translated into statements in an imperative language.

As an example of the similarities between monads and imperative programs, consider a software program for reversing an array:

\begin{code}
reverseS :: SArr Int32 -> Software ()
reverseS arr =
  for 0 (len `div` 2) $ \ix -> do
    aix <- getArr arr ix
    ajx <- getArr arr (len - ix - 1)
    setArr arr ix ajx
    setArr arr (len - ix - 1) aix
  where
    len = length arr
\end{code}

\noindent Its type signature tells us that it takes an array over 32-bit integers as input and produces a software program---notice that the array type \codei{SArr} is prefixed with an \codei{S} in order to show that it is intended to be used with software statements. The return type is empty as the array is reversed in place.

% The implementation of \codei{reverseS} certainly has the look and feel of a imperative program, sans a few syntactical differences. As a result, the translation of \codei{reverseS} to C code is straightforward: we simply translate each statement to their corresponding statement in C. We can even translate each statement individually since monads take care of the program structure.

% \codei{reverseS} makes use of two array operations for reading and writing to an array, \codei{getArr} and \codei{setArr}, which behave as you would expect them to: \codei{getArr} takes an array and an index, and returns the array's value at that index; \codei{setArr} takes an array, an index and a value, and stores the value in the array.

% For each of these indices, \codei{ix}, it reads two values from the array at the leftmost and rightmost places, offset by the index. Having read and stored these two values into the \codei{aix} and \codei{ajx} variables, they are then put back into the array at the opposite place. This process of flipping pairs of values will eventually result in a reversed array when the two indexed values meet in the middle. 

While the type of \codei{reverseS} is that of a software function, there's nothing software specific about it. For-loops and arrays are both part of most imperative languages, and we could just as well have implemented the same reverse function in hardware. In fact, we can define the hardware version by simply changing the previous function's type signature while keeping its body intact:

\begin{code}
reverseH :: HArr Int32 -> Hardware ()
reverseH arr =
  for 0 (len `div` 2) $ \ix -> do
    aix <- getArr arr ix
    ajx <- getArr arr (len - ix - 1)
    setArr arr ix ajx
    setArr arr (len - ix - 1) aix
  where
    len = length arr
\end{code}

The fact that we are able to define both the \codei{reverseS} and \codei{reverseH} using the same function body hints that having them marked as software and hardware programs was unnecessarily restrictive. After all, the function only requires its language to support for-loops, arrays, and a few numerical operations.

Functions which are not limited to either hardware or software are supported by the co-design language through its hierarchy of type classes. That is, as we used Haskell's \codei{Num} class in section~\ref{embedded} to accept any numerical value in our dot-product, we can also use type classes to accept any language which support the classes' functions. As for the reverse function, which makes use of a for-loop and array operations, we can give it the following type signature:

\begin{code}
reverse :: (Monad m, Arrays m, Control m, TypeM m Int32)
        => Arr m Int32 -> m ()
\end{code}

\noindent In order to make the function language agnostic, the previous array types of \codei{SArr} and \codei{HArr} have been substituted for the generic array type \codei{Arr}, which is parameterized on the monad \codei{m} rather than associated with a specific language. The general idea behind \codei{Arr} is that it will turn into \codei{SArr} or \codei{HArr} when instantiated with their respective monads.

Three new constraints have been introduced, namely the \codei{Arrays}, \codei{Control}, and \codei{TypeM} type classes. Where the first two ensure \codei{m} supports arrays and for-loops, whereas the third one states that a 32-bit integer is a valid type in \codei{m}. The two type classes for \codei{Arrays} and \codei{Control} are defined as follows:

\begin{code}
class Monad m => Arrays m where
  type Arr m
  newArr :: TypeM m a => Exp m Length -> m (Arr m a)
  getArr :: TypeM m a => Arr m a -> Exp m Index -> m a
  setArr :: TypeM m a => Arr m a -> Exp m Index -> a -> m ()

class Monad m => Control m where
  for :: (TypeM m a, Integral a) => Exp m a -> Exp m a -> (Exp m a -> m ())
      -> m ()
\end{code}

\noindent Where each class lists their associated functions and in the case of arrays, the type to use with them. \codei{Exp} represents the expression type associated with \codei{m}. As functions like these are quite common in imperative programs, we provide a short-hand for type classes with common computational functions called \codei{MonadComp}:

\begin{code}
type MonadComp m = (Monad m, References m, Arrays m, Control m)
\end{code}

% The \codei{TypeM} and \codei{Exp} types introduced here are quite similar to the earlier \codei{Type} and \codei{Exp} types from section~\ref{haskell}. In fact, the latter two types are defined in terms of the general ones but applied to the softare monad, as we used them with examples that were compiled to C code.

While the software and hardware monads both support the above array and control operations, the co-design library also provides classes of operations that are only supported by software but not hardware, and vice versa---like processes in hardware or IO in software:

\begin{code}
class HardwareMonad m => Process m where
  process :: [Name] -> m () -> m ()
\end{code}

\noindent Monads still form the base of the class hierarchy, but functions intended for either software or hardware branches also require that \codei{m} is an extension of their respective monads.

At this point we should note that types introduces in this section are slightly different from those found in section~\ref{embedded}. For instance, the array type now has an extra parameter \codei{m}. These differences are the result of our wish to simplify the function types in the earlier section and, in the case of arrays, can be unified by using either \codei{SArr} or \codei{HArr}.

With the new types and classes, we revisit the dot product from section~\ref{embedded} and reimplement it as a generic function:

\begin{code}
dotSeq :: (MonadComp m, TypeM m a, Num a) =>
  Arr m a -> Arr m a -> Program (Exp m a)
dotSeq x y = do
  sum <- initRef 0
  for 0 (min (length x) (length y) $ \ix -> do
    a <- getArr x ix
    b <- getArr y ix
    modifyRef sum $ \s -> s + a * b
  getRef sum
\end{code}

\noindent Aside from its type signature, which now includes the constraints \codei{MonadComp} and \codei{TypeM}, the function is the same as its previous incarnation.

As an example of a larger function, we also implement the full FIR filter:

\begin{code}
firSeq :: (MonadComp m, TypeM m a, Num a) =>
  Arr m a -> Arr m a -> m (Arr m a)
firSeq bs xs = do
  taps <- newArr (length bs)
  ys   <- newArr (length xs)
  for 0 (length bs) $ \ix -> do
    setArr taps ix 0
  for 0 (length xs) $ \ix -> do
    for 1 (length bs) $ \jx -> do
      tmp <- getArr taps (jx - 1)
      setArr taps jx tmp
    x <- getArr xs ix
    setArr taps 0 x
    o <- dotSeq bs taps
    setArr ys ix o
  return ys
\end{code}

\noindent The filter itself is fairly straightforward: inputs are shifted onto an array holding the filter's taps and with each shift one output is calculated by the dot product of the current coefficients and taps. The taps themselves are stored in an array, which is initialized with zeroes.

While the above filter is suitable for a software implementation, it is perhaps not ideal as a hardware design: signal processing in C is often done with arrays over chunks of the input, while a hardware design makes use of signals and processes to drive a continuous filter. In the case of our FIR filter, the change to hardware is however quite small: we simply swap the input and output arrays for signals and change the outer for-loop into a process. Rewriting programs at this scale is a kind of optimization wich we think developers are comfortable with. 

% and as long as layout experimentation, 

% Connecting the FIR filter to a simple main program that supplies an example arrays for its coefficients and input lets us instantiate the code in, for example, the software monad and compile it to C:

% \noindent Note that, in order to make the filter implementation a bit shorter, we given the output signal as an argument to the filter.

% Making the change from generic arrays to signals means that we also have to update the function's body in order to reflect its new types. For signals, the difference is that values are now processed one by one instead of chunks, that is, rather that iterating over an input array we will have to process an input signal and react to its changes in value with a process:

% \begin{code}
% firH N b xs ys = do
%   taps <- initArr (replicate N 0)
%   ys   <- initSignal 0
%   process (xs .: []) $ do
%     for 1 (lit N) $ \jx -> do
%       tmp <- getArr taps (jx - 1)
%       setArr taps jx tmp
%     x <- getSignal xs
%     setArr taps 0 x
%     setSignal ys (dot b taps)
%   return ys
% \end{code}

% \noindent Note that, the arrays used for taps and coefficients are held by signals.

% Connecting the hardware filter to a main program body that supplies it with its inputs and compiling it produces the following VHDL design:

\section{Instructions}
\label{instr}

The co-design language is inspired by the work of~\cite{BjornBenny} and by the Operational Monad~\cite{Operational} and is as such based on a monadic representation of imperative programs. Like our inspiration, these programs capture a monadic computation as an algebraic data type. However, unlike our inspiration, we also take into account the fact that languages support different instructions, types and expressions. The program type is therefore parameterized on its instruction type and a type-level list of types associated with the language:

\begin{code}
data Program instr fs a
\end{code}

\noindent As programs are a deep embedding of monads they instantiate Haskell's monad class:

\begin{code}
instance Monad m => Functor     (Program instr fs)
instance Monad m => Applicative (Program instr fs)
instance Monad m => Monad       (Program instr fs)
\end{code}

The general idea behind our program type is that it allows for instructions to be separated from their sequencing, since an instruction's effect will only depend on its interaction with other instructions. That is, Haskell's monadic syntax ensures that any instructions we use in our programs are sequenced correctly. As a consequence of this separation, the task of implementing a language based on \codei{ProgramT} is the same as writing an interpreter for the language's instructions. In particular, we can define a generic interpreter for programs that maps them to their intended meaning:

\begin{code}
interpret :: (Interp i m fs, HFunctor i, Monad m) => Program i fs a -> m a
\end{code}

\codei{interpret} lifts a monadic interpretation of instructions, which may be of varying types, to a monadic interpretation of the whole program. By using different types for the monad \codei{m}, one can implement different ``back ends'' for programs. For example, interpretation in Haskell's \codei{IO} monad gives a way to \emph{run programs}, while interpretation in a code generation monad can be used to make a \emph{compiler}. The interpretation of an instruction set \codei{i} to the monad \codei{m} is given by \codei{Interp}:

\begin{code}
class Interp instr m fs where
  interp :: instr '(m,fs) a -> m a
\end{code}

Note that \codei{interpret} also require that its instructions are higher-order functors, parameterized on the program monad that they are part of---the instructions here are actually given a list of parameters, but the interpreter is only interested in its first member. There is however nothing stopping us from having instructions with more parameters. The \codei{HFunctor} class of higher-order functors is defined as follows:

\begin{code}
class HFunctor h where
  hfmap :: (forall b . f b -> g b) -> h '(f, fs) a -> h '(g, fs) a
\end{code}

Having instructions be parameterized on the program monad makes it possible to define instruction sets compositionally using, for instance, a technique like Data Types \`{a} La Carte~\cite{DTC}. In the original Operational Monad this could be only done for simple instructions, but with our new program type it can be done even for \emph{control instructions}---instructions that take programs as arguments. Extensible instructions sets are particularly useful for the co-design language, as its hardware and software instructions can be reused for new platforms: we only need to add support for its intrinsic functions.

As an example of how an new instruction can be defined, we introduce the \codei{If} construct:

\begin{code}
data ControlCMD fs a where
  If :: exp Bool -> prog () -> prog () -> ControlCMD (P3 prog exp pred) ()
\end{code}

\noindent Note the use of the type parameter \codei{prog} to refer to sub-programs, \codei{exp} refers to pure expressions, and \codei{pred} refers to type predicates. Although \codei{pred} is not used in the definition of \codei{If}, it is used by other instructions and therefore included here to keep the parameter lists consistent. \codei{P3} is a short-hand for a parameter list of three arguments.

Assuming we have already defined a few other instructions like \codei{If}, we can now make program types that combine several instructions with the \codei{:+:} operator from Data Types \`{a} La Carte; for example:

\begin{code}
type MyProgram = Program (If :+: Reference :+: ...) (P2 Exp Pred)
\end{code}

\noindent The recursive \codei{Program} type then sets the type of sub-programs in \codei{If} to \codei{MyProgram}, with \codei{Exp} and \codei{Pred} used as the expression and predicate types.

In order to use the \codei{interpret} function, \codei{If} needs to be an instance of the \codei{Interp} and \codei{HFunctor} classes. Both \codei{Interp} and \codei{HFunctor} do however distribute over \codei{:+:}, which means that it is possible to interpret any instruction set as long as its individual instructions have instances for the respective classes. The \codei{HFunctor} instance is straightforward:

\begin{code}
instance HFunctor ControlCMD where
  hfmap f (If c thn els) = If c (f thn) (f els)
\end{code}

\noindent Interpretation of \codei{If} in, for example, the \codei{IO} monad could look as follows:

\begin{code}
instance Interp ControlCMD IO fs where
  interp (If b tru fls) = if evalExp b then tru else fls
\end{code}

\noindent Where \codei{evalExp} is an evaluator for the expression language.

\section{Expressions}
\label{expr}

A language embedding based on monads gives users a representation of the statements in an imperative program, but most meaningful programs also include a notion of pure expressions. These expressions contain a combination of one or more values, constants, variables and operators that our co-design library interprets and computes to produce a new value. As a small example, consider a function for squaring a value:

\begin{code}
square :: (Num (exp a), Type exp a) => exp a -> exp a
square a = a * a
\end{code}

\noindent Note that the \codei{Type} constraint on \codei{a} is slightly different than \codei{TypeM} from section~\ref{program}, as \codei{Type} accepts expressions rather than monads for its first argument.

% that before as we use \codei{Type} instead of \codei{TypeM}: the former is designed to be used with expressions rather than monads.

Programming with expressions in our co-design language is evidently quite similar to how its done in regular Haskell. For instance, applying the squaring function to a value of $5$ is equivalent to the mathematical expression $5*5$ which evaluates to $25$. However, the expressions used in our co-design language are deeply embedded, and as we saw in section~\ref{domain}, that means evaluation isn't the only interpretation they support. In fact, by substituting the general \codei{exp} type for either the software or hardware expression type, \codei{SExp} and \codei{HExp}, we can also compile the expression.

In simple expressions, like the above squaring function, the resulting value is usually one of various primitive types such as signed and unsigned numerical, floating point, and logical. However, in more elaborate expressions it can be a complex data type. For example, we can define an expression over a pair of values, and we can define functions over these pairs as well:

\begin{code}
dist :: (SExp Float, SExp Float) -> (SExp Float, SExp Float) -> SExp Float
dist (x1, y1) (x2, y2) = sqrt (dx**2 + dy**2)
  where
    dx = x1 - x2
    dy = y1 - y2
\end{code}

\codei{dist} computes the distance between two points in a plane, where points are represented as a pair of coordinates. These pair are however only syntactic suger, and no pairs will appear in the generated code. In fact, expressions provide a number of abstractions that we are accustomed to as functional programmers, like let-bindings:

\begin{code}
class Let exp where
  share :: (Type exp a, Type exp b) => exp a -> (exp a -> exp b) -> exp b
\end{code}

Abstractions are one of the hallmarks of functional programming and let users avoid unnecessary detail and mundane operations, such as the sharing of values through let-bindings. At the same time, abstractions can complicate the compiler and make it harder to generate efficient code. To circumvent this problem the co-design language makes use of two expression types: one with only primitive operations that is easy to compile, and one with features like let-bindings that is easy to program with.

In order to avoid having two separate instances of each interpretation for expressions, which is tedious and error-prone task, we provide an elaboration from the feature rich expressions into program snippets over the primitive expressions:

\begin{code}
elaborateSExp :: SExp a -> Program SIns (P2 CExp SType) (CExp a)
\end{code}

\noindent Where \codei{SIns} and \codei{SType} are the software instruction set and type predicate, and \codei{CExp} are the primitive expressions. The program wrapping is necessary as, for instance, let-bindings are translated into references. Fortunately, programs are regular monads like any other, we can use the \codei{interpret} function to elaborate entire software programs

\begin{code}
elaborateSoft :: Software a -> Program SIns (P2 CExp SType) a
elaborateSoft = interpret
\end{code}

\noindent Assuming we use \codei{elaborateSExp} to give an \codei{Interp} instance.

An evaluator for software programs can thus be defined by stringing together the elaboration of expressions with an interpreter for programs:

\begin{code}
runSoft :: Software a -> IO a
runSoft = interpert . elaborateSoft
\end{code}

This approach to expressions has several benefits: the translation is typed, which rules out many potential errors, and is easier to write than a complete translation into source code; the low-level expression type is reusable, and can be shared as an elaboration target between multiple high-level expression types.

\section{Communicating Components}

The ability to write generic programs that our co-design library means users can easily experiment with different language implementations of their functions. Most interesting heterogeneous programs does however include a mixture of software and hardware fragments, where the different parts communicate with each other. In the kind of FPGAs with embedded systems that we consider, communication is typically done over an AXI4 or AXI4-lite interconnect. 

Full AXI4 offers a range of interconnects that include variable data and address bus widths, high bandwidth burst and cached transfers, and various other transaction features that makes it useful for streaming. A lighter version of the AXI4 interconnect is offered through AXI4-lite, which is a subset of the full specification that forgoes the streaming features for a simpler communication model that writes and reads data one piece at a time. While full AXI4 certainly has its uses, there is no need for such features in the examples we have shown so far. The lighter interconnect offered by AXI4-lite is however a better fit, and will be the focus in this section.

% Although burst writing of arrays is desirable they are usually small enough to not impact performance.

Five channels make up the bulk of the AXI4-lite specification: the read and write address channels, the read and write data channels, and the write acknowledge channel. These five channels are represented in VHDL as signals, driven by processes that implement the associated handshaking and logic for reading and writing. Signals behave very much like the references found in C, and processes is a kind of function runs automatically once any of its input changes. Both signals and processes are supported by our co-design library, and the whole AXI4-lite interface is in fact implemented within the co-design library:

% ---while the full AXI4 interface could certainly be implemented as well, we have yet to do so.

\begin{code}
axi4lite ::
  => Signature a
  -> Signature (
          Sig (Bits 32) -- ^ Write address.
       -> Sig (Bits 3)  -- ^ Write channel protection type.
       -> Sig Bit       -- ^ Write address valid.
       -> Sig Bit       -- ^ Write address ready.
       -> Sig (Bits 32) -- ^ Write data.
       -> Sig (Bits 4)  -- ^ Write strobes.
       -> Sig Bit       -- ^ Write valid.
       -> Sig Bit       -- ^ Write ready.
       -> Sig (Bits 2)  -- ^ Write response.
       -> Sig Bit       -- ^ Write response valid.
       -> Sig Bit       -- ^ Response ready.
       -> Sig (Bits 32) -- ^ Read address.
       -> Sig (Bits 3)  -- ^ Protection type.
       -> Sig Bit       -- ^ Read address valid.
       -> Sig Bit       -- ^ Read address ready.
       -> Sig (Bits 32) -- ^ Read data.
       -> Sig (Bits 2)  -- ^ Read response.
       -> Sig Bit       -- ^ Read valid.
       -> Sig Bit       -- ^ Read ready.    
       -> ())
\end{code}

\codei{axi4lite} accepts a hardware component and automatically connects it to an AXI4-lite interconnect, moving values between the component and the read and write channels of the interconnect. The connected component can then be loaded into a synthesis tool like Vivado~\cite{feist2012}, which results in a physical design that can be put onto, for example, the logic blocks of an FPGA.

% A function called \codei{axi_ligth} takes a hardware program and hooks it up to an AXI4-lite interconnect, and the wrapped hardware component can then be compiled to VHDL and loaded into a synthesis tool like Vivado, which will turn it into a physical design that can be put onto the FPGA.

With a component on the hardware we can interface with it using portmaps as usual, but with the physical address of the component in hand we can also memory-mapped I/O to access it from software. Having memory-mapped a component causes them to share address space with the memory of whatever software program they are running in. That is, a memory-mapped component can be reached from software by simply writing to and reading from pointers.

% The components monitor a processors address buss and, whenever an address for component is accessed, they forward the request to the address component.

The co-design library provides a function called \codei{mmap} that preforms the necessary memory-mapping when given a component and its address:

\begin{code}
mmap :: String -> Component a -> Software (Pointer (Soften a))
\end{code}

\noindent Note that the resulting memory pointer has ``soften'' its type, which replaces hardware types like signals with their corresponding type in software. The translation between hardware and software types is described by the type family \codei{Soften}, part of which is define as follows:

\begin{code}
type family Soften a where
  Soften ()           = ()
  Soften (Sig a -> b) = SRef a -> Soften b
  --dotLine
\end{code}

At this point, we have provided a means to load a hardware component onto, for instance, an FPGA's logic blocks and then have it memory-mapped into software. The remaining step is a method to call the component and get its result. In order to call the component, we must first construct a list of argument using these three functions:

\begin{code}
nil   :: Argument ()
(:>)  :: SType a => SRef a -> Argument b -> Argument (SRef a -> b)
(:>>) :: SType a => SArr a -> Argument b -> Argument (SArr a -> b)
\end{code}

\noindent Where \codei{nil} creates an empty argument list, and the two infix functions \codei{(:>)} and \codei{(:>>)} extends an argument list with a reference and an array, respectively. The argument list itself is a typed heterogeneous list that ensures we use the expected number of arguments and that all intermediate types match.

Calling a component once we have our arguments is done by using \codei{call}:

\begin{code}
call :: Pointer a -> Argument a -> Software ()
\end{code}

\noindent Which goes through the argument list and writes each value that's marked as an input, while those marked as outputs store the result read from the component.

\end{document}
