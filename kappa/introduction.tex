%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%       oe    
%     .@88    
% ==*88888    
%    88888    
%    88888    
%    88888    
%    88888    
%    88888    
%    88888    
%    88888    
% '**%%%%%%** 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[../main.tex]{subfiles}
\begin{document}

\chapter{Introduction}
\label{intro}

Embedded systems are, in brief, any computer system that is part of a larger system but relies on its own microprocessor. It is embeddde as part of a larger machine to sovle a particular task, and often does so under memory and real-time constraints. Embedded systems have been have been around for decades, and still control many devices in common use today~\cite{barr2006}. For example, modern cars contain a number of embedded systems, each controlling a small function of the car; one system might control the brakes, while another displays information to the dashboard. In most cases, these embedded sub-systems are all connected together in a network. 

Developing software for embedded systems, in most cases, requires good knowledge about the hardware on which the software is supposed to run. Because embedded systems are typically designed with a task in mind, their hardware systems are often built with most cost-effective processor that meets the performance requirements. So developers must ensure their computations are efficient. Every line of code counts.

As important as computational power is for embedded systems, limiting their power consumption presents an equally important issue in their architectural design~\cite{mudge2001}; the trend of trading power for performance cannot continue indefinitely. Containing the growth in power requires architectural improvements, with specialized computing for specialized tasks.

% typical house hold processors of today have a power density of 70W and upwards, which is seven times that of a typical hot plate

% Heterogeneous computing present new challenges in software design that are not found in the development for typical homogeneous systems~\cite{kunzman2011}. The multiple processing units present in a heterogeneous system raises all of the issues associated with homogeneous parallel systems, while the heterogeneity in the system gives rise to new issues due to dissimilarity in system development and capability.

Heterogeneous computing represents an interesting development towards the goal of energy efficient computing, and refers to systems that use more than one kind of processing units. These heterogeneous systems gain their performance and energy efficiency not just by combining several processors, but rather by incorporating different kinds of co-processors that provide specialized processing capabilities to handle a particular task. Their efficiency and computational power comes at a cost of increased programming burden in terms of code complexity and portability, as hardware specific code is interleaved with software code to describe its various components and to handle any communication between co-processors.

% The efficiency and computational power of heterogeneous systems thus comes at a cost of increased programming burden in terms of code complexity and portability, as hardware specific code is interleaved with application code to handle any communication between co-processors.

% Furthermore, the structure of application code typically vary between co-processors and any code written for one therefore requires modification when given a new target. In fact, despite all the advantages heterogeneous systems offer, their use so far has been mostly restricted to hardware programmers.

A substantial amount of research has gone into addressing the challenges of programming for embedded heterogeneous systems, opening them up for programmers without a background in hardware or embedded system design. Hardware description languages are however still the most commonly used tools, together with C for specific co-processors and GPUs. While these languages are good for extracting maximum performance from a processor, they provide little to no abstractions for alleviate the task of programming for heterogenous systems.

% such as VHDL and Verilog

% These hardware description languages have revolutionized hardware design but suffer from a lack of expressiveness and standardization -- there is a mismatch between description and synthesized hardware.

% Designers have therefore looked for alternative solutions, where one of the more well-known approaches is synthesis of high-level languages like C~\cite{graphics2008, ghenassia2005}. Compiling high-level languages to a hardware description has great appeal, but finding a translation between the two has however proven to be difficult; sequential programs are often a bad fit for the parallelism inherent to most hardware architectures.

Another group of languages that have shown success in describing hardware designs are functional languages~\cite{sheeran2005}. Higher-order functional languages in particular, where hardware descriptions are first-class objects, offer a particularly useful abstraction mechanism~\cite{baaij2010, bjesse1998, gill2010}. Another beneficial attribute of these languages is their purity, which enables reasoning about function (de-)composition as a seperate matter from their evaluation. Bluespec SystemVerilog~\cite{nikhil2004}, for example, is a functional language that provides high-level synthesis of its rule based programs into RTL.

% Bluespec~\cite{nikhil2004}

% That is, functional programming separates the definition and evaluation of its functions, and functions could, for example, be run in parallel, as long as their dependencies are covered. Functional languages are however rarely considered for embedded system development, as its difficult to give performance guarantees and resource bounds for its programs.

This thesis presents the first steps towards a functional programming language intended for embedded system development, where the entire design process of heterogeneous systems can be expressed. The language aims to go further than the aforementioned functional languages, and does not rely solely on hardware descriptions; some components are better described using sequential algorithms directly, rather than having one generated from a hardware description.

Instead of taking on the full challenge of heterogeneous programming head on, we are currently interested in a more modest approach: develop a language where experiment with software and hardware boundaries, embed it in Haskell, and see how far we can get in the design of a modern FPGA. The language aims to raise the abstraction level of numerical processing and digital signal processing for embedded systems.

Modern FPGAs show a lot of promise in heterogeneous computing as they combine programmable logic, discrete components and various co-processors with a good performance per Watt ration, all on a single system. Although this diversity of components is good for performance, it does make the system harder to program: its programmable logic is often described in a hardware description language while co-processors are described in a low-level dialect of C.

So, starting with a single functional program, our co-design library is faced with three tasks: generate software for the application parts, hardware for the logical parts, and a mixture of software and hardware for the communication between components. As an example, consider a dot product, also known as a scalar product. The dot product is an algebraic operation that takes two vectors of equal length and returns the sum of the products of the corresponding entries of the two vectors:

% In an imperative setting, like that of C, the dot product's result could be computed with a single for loop that iterates over the two input arrays and calculates the sum of their products, one pair at a time. Such a sequential solution is possible to describe in our functional language, as it provides a model of imperative programs:

\begin{code}
dot :: Vec Int32 -> Vec Int32 -> Prog (Exp Int32)
dot xs ys = sum (zipWith (*) xs ys)
\end{code}

Note that the dot function does not mention any software or hardware specific types or functions; \codei{dot} only makes use of vectors and a few numerical expressions. As a result, the function's type is kept general in the sense that it can be realized in both hardware and software. However, lets assume for the sake of our example that we wish to put the dot product on hardware. The function itself can already be compiled to VHDL, but in order to make it accessible in software we must first give it a signature:

\begin{code}
component :: Signature (Vec Int32 -> Vec Int32 -> Exp Int32)
component = inputVec 4 $ \xs -> inputVec 4 $ \ys -> returnVal $ dot xs ys
\end{code}

\noindent Signatures, like the above one, describes a function's type in such a way that it can be inspected from within Haskell. In the case of our dot product, the signature tells us that it takes two input vectors of length four and returns a single value.

Having access to a description of hardware component enables us to connect it with an interconnect and put onto hardware as a physical component, which can then be memory-mapped into from software. Having memory-mapped a component causes them to share address space with the memory of whatever software program they are running in. That is, the component can be reached by simply reading and writing to ordinary pointers into the components physical address.

With the hardware component address in hand, we can write a small software program that addresses our dot product component and feeds it with two example arrays and prints its result:

\begin{code}
program :: Soft ()
program = do
  dot <- mmap "0x83C0_0000" component
  xs  <- initArray [1,2,3,4]
  ys  <- initArray [5,6,7,8]
  ref <- call dot (xs .: ys)
  v   <- getRef ref
  printf "sum: %d" v
\end{code}

\noindent Here, the memory mapping itself is done by the \codei{mmap} function, and returns a software pointer to the components address. The component is then called with two example arrays and returns a reference to its result, which is printed to standard output.

Our example program has the look and feel of an imperative program, sans a few syntactical differences. This similarity is very much intentional, as the library, at its core, is a model of the imperative languages C and VHDL. In fact, the operations in our example can be directly translated into statements in C---\codei{mmap} and \codei{call} are specific to C. Compiling the example yields the following code:

% The vector library, as shown in the implementation of the dot product, is one of our user-facing libraries that are built on ...

\begin{code}
// C code and VHDL snippet (minus the communicating bits).
\end{code}

% The kind of imperative program ..

% \noindent Note that the list of arguments for the component is constructed in such a way that matches their types against the type of the component, ensuring ...

%\begin{code}
%dot :: (MonadComp m, TypeM m Int32) => Arr m Int32 -> Arr m Int32
%    -> m (Ref m Int32)
%dot xs ys =
%  do sum <- initRef 0
%     for 0 len $ \ix ->
%       do x <- getArr xs ix
%          y <- getArr ys ix
%          t <- getRef sum
%          setRef sum (t + x * y)
%     return sum
%  where
%    len = max (length xs) (length ys)
%\end{code}

%Note that the above \codei{dot} function does not mention any software specific types; \codei{dot} only makes use of two array, a reference, a for-loop, and a few logical and numerical expressions. As a result, the function's type is kept general in the sense that its parameterized on the language \codei{m} that it will eventually be instantiated in---whether \codei{m} is a software or hardware language is not yet decided. The constraint \codei{MonadComp} on \codei{m} ensure that whichever language \codei{m} ends up as will support the necessary operations, and had we picked a specific language for \codei{m} we would also have access to operations specific to that language.

%While the imperative implementation of the \codei{dot} function is already convenient for software realization, with the optional use as a hardware design, a pure and functional description can sometimes yield a nicer description. For this reason, our language also provide a library based on push and pull vectors~\cite{claessen2012} that facilitates a nice syntax for writing functions over vectors. For example, the dot product could be reimplemented as a function based on pull vectors:

%\begin{code}
%dot :: (Vector exp, Type exp Int32) => Pull exp Int32 -> Pull exp Int32
%    -> exp Int32
%dot a b = sum (zipWith (*) a b)
%\end{code}

%\noindent Which is parameterized on a pure expression language \codei{exp} rather than a stateful language.

% like \codei{m} in the previous incarnation of \codei{dot}.

%The dot product and its two implementations are both combinatorial in the sense that their output only depend on the current input. Most types of vector or signal processing do, however, carry some form of state. For this reason, we also provide a signal processing library for synchronous signal processing that provides a means to promote pure values and functions to work over signals and a delay operator for access to a signal's previous value. While this set of operations may appear innocent, they allow one to any express any kind of sequential signal network. For example, we can define an edge detector that checks at each instant if the value of a signal has changed:

% by comparing its current and previous values:

%\begin{code}
%edge :: Signal exp Bool -> Signal exp Bool
%edge sig = zipWith (/=) sig (delay false sig)
%\end{code}

% \noindent Where \codei{delay} prepends the input boolean signal with a value of \codei{false}.


%\begin{code}
%program :: Software ()
%program =
% do -- todo: read input arrays in a nice way.
%    r   <- dot xs ys
%    sum <- getRef ref
%    printf "sum: %d" sum
%\end{code}

%\begin{code}
%dot :: (Monad m, Arrays m, Control m, TypeM m Int32)
%  => Arr m Int32 -> Arr m Int32 -> m (Exp m Int32)
%\end{code}

%\begin{code}
%dotSig :: Signature (HArr Int32 -> HArr Int32 -> HRef Int32)
%dotSig = inpArr 16 $ \xs -> inpArr 16 $ \ys -> ret $ dot xs ys
%\end{code}

%\begin{code}
%offloaded :: Software ()
%offloaded =
%  do -- todo: read input arrays in a nice way.
%     comp <- mmap "0x83C0_0000" dotSig
%     r    <- newRef
%     call comp (xs :> ys :> r)
%     sum <- getRef r
%     printf "sum: %d" sum
%\end{code}

This thesis consists of two parts. Part I is a general introduction to the field and puts the appended papers into context. Part II contains the appended papers.

% ToDo: Limit to FPGAs.

\end{document}
