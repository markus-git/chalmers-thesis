%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%       oe    
%     .@88    
% ==*88888    
%    88888    
%    88888    
%    88888    
%    88888    
%    88888    
%    88888    
%    88888    
% '**%%%%%%** 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[../paper.tex]{subfiles}
\begin{document}

\chapter{Introduction}
\label{intro}

An embedded system is, in brief, any computer system that is part of a larger system but relies on its own microprocessor. It is embedded as part of a larger machine to solve a particular task, and often does so under memory and real-time constraints, using most cost-effective hardware that meets the performance requirements. Developing for embedded systems therefore requires good knowledge about the architecture on which the a program is supposed to run. Not only should computations be efficient, but also take full advantage of the custom hardware; every line of code counts.

% Embedded systems have been around for decades, and still control many devices in common use today~\cite{barr2006}. For example, modern cars contain a number of embedded systems, each controlling a small function of the car; one system might control the brakes, while another displays information to the dashboard.

% In most cases, these embedded sub-systems are all connected together in a network.

% Developing software for embedded systems requires good knowledge about the architecture on which the a program is supposed to run. This is because an embedded system is typically designed with a particular task in mind and consists of the most cost-effective hardware that meets the performance requirements. Developers must therefore ensure that not only are their computations efficient, but also take full advantage of the custom hardware; every line of code counts.

As important as computational power is for embedded systems, limiting their power consumption presents an equally important issue in their architectural design~\cite{mudge2001}---the trend of trading power for performance cannot continue indefinitely. Containing the growth in power requires architectural improvements, with specialized computing for specialized tasks. Heterogeneous computing represents an interesting development towards this goal, and refers to systems making use of more than one kind of processor. The benefit of these systems does not come from simply combining several processors, but rather by incorporating different kinds of co-processors that provide specialized processing capabilities to handle a particular task.

A substantial amount of research has gone into addressing the challenges of programming for embedded heterogeneous systems, opening them up for programmers without a background in hardware or embedded system design. Hardware description languages are however still the most commonly used tools, together with C dialects for specific co-processors. While such low-level languages are good for extracting maximum performance from a processor, their portability is severely limited, design exploration is tedious at best, and moving entire programs between C and hardware descriptions is a major undertaking.

Another group of languages that show great promise in describing hardware designs are the functional languages. Higher-order functional languages in particular offer an especially useful abstraction mechanism~\cite{baaij2010, bjesse1998, gill2010} through higher-order functions and lazy evaluation. These features allow for program designs to be treated as first-class objects, and larger applications can be constructed by composing such designs in a modular fashion. Thanks to lazy evaluation, only the relevant parts of these smaller designs will show up in the generated source code. Despite the benefits of functional languages, they are rarely considered for embedded system development. One reason for their low adoption is that it is difficult to give performance guarantees and resource bounds.

% Furthermore, the type-system and classes of functional languages make it possible to precisely record a function's operational dependencies in its type---functions can depend on the operations they use rather then the software or hardware component they're designed for.

This thesis is the first few steps towards a functional programming language for embedded heterogeneous systems, like that of a modern FPGA. Instead of taking on the full challenge of heterogeneous programming head on, a more modest approach is currently being explored: develop a hardware software co-design language, embed it in Haskell, and see how far that can go. The language is staged and utilizes the rich type system of its host language to facilitate design exploration. Furthermore, a vector and a signal processing language are introduced to accompany the co-design language, and provides useful abstractions for their respective programming domains.

As an example of the co-design language, consider a dot product, also known as a scalar product. The dot product is an algebraic operation that takes two vectors of equal length and returns the sum of products for corresponding entries in the two vectors:

\begin{equation}
a \cdot b = \sum_{i=1}^{n}a_{i}b_{i} = a_{1}b_{1} + a_{2}b_{2} + \cdots + a_{n}b_{n}
\end{equation}

With an imperative language like C, the dot product's result could be computed with a single for-loop that iterates over the two input arrays and calculates the sum of their products, one step at a time. Such a sequential solution can be implemented in the co-design language as well:

\begin{code}
dotSeq :: Arr Int32 -> Arr Int32 -> Program (Exp Int32)
dotSeq x y = do
  sum <- initRef 0
  for 0 (min (length x) (length y)) $ \ix -> do
    a <- getArr x ix
    b <- getArr y ix
    modifyRef sum $ \s -> s + a * b
  getRef sum
\end{code}

While the above function is faithful to its corresponding implementation in C, its low-level design has forced a focus on implementation details rather than the mathematical specification of the dot product: it carefully has to make sure indices and lengths are correct and sum is calculated manually in steps. A more idiomatic solution is to make use of the vector language:

% In this situation, where the function can be succinctly expressed as a sum over products, we would be better off using the vector language instead. In fact, the same dot product can be implemented with vectors in a single line:

\begin{code}
dotVec :: Vec Int32 -> Vec Int32 -> Program (Exp Int32)
dotVec x y = sum (zipWith (*) x y)
\end{code}

\noindent where summation and element-wise multiplication is wholly handled by the smaller \codei{sum} and \codei{zipWith} functions.

At this point we should note that neither version of the dot product mentions any software or hardware specifics and, as such, can be realized in both software and hardware. The dot product can be compiled to software as it is. If we want to put it onto hardware instead, we must first give it a signature that lists its two inputs and its output:

\begin{code}
dotSig :: Component (Arr Int32 -> Arr Int32 -> Sig Int32)
dotSig = inputVec 4 $ \x -> inputVec 4 $ \y -> returnVal $ dotVec x y
\end{code}

\noindent The signature of a component lets our compiler inspect its input and output ports, for example to compile it to a hardware design or hook it up to an AXI4-lite interconnect---a standard for communication between software and hardware components.

Having wrapped our \codei{dotSig} component in an AXI4-lite interconnect and then put it onto hardware, its possible to reach it from software through memory-mapped I/O. The general idea is that a memory-mapped component will share its address space with the software program, that is, a memory-mapped hardware component can be reached from software by simply reading and writing to regular pointers. As an example, we write a small software program that calls \codei{dotSig} and prints its result:

\begin{code}
program :: Software ()
program x y = do
  dot <- mmap "0x43C00000" dotSig
  xs  <- initArray [1,2,3,4]
  ys  <- initArray [5,6,7,8]
  r   <- newRef
  call dot (xs .: ys .: r .: nil)
  res <- getRef r
  printf "sum: %d" res
\end{code}

The above software program first brings our \codei{dotSig} hardware component into scope by calling the memory-mapping function \codei{mmap} with the components physical address---which we acquired during synthesis---and signature. Two arrays are then declared, one for each input of the hardware component, and a reference for its output. Lastly, the component is called with an argument list that matches its signature, and its result is read from the reference that holds it and printed to standard output.

\end{document}
