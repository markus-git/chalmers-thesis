%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%   cuuu....uK    
%   888888888     
%   8*888**"      
%   >  .....      
%   Lz"  ^888Nu   
%   F     '8888k  
%   ..     88888> 
%  @888L   88888  
% '8888F   8888F  
%  %8F"   d888"   
%   ^"===*%"`
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[../paper.tex]{subfiles}
\begin{document}

\chapter{Concluding Remarks}

\section{Related Work}
\label{related}

Sheeran pioneered the use of functional languages in hardware design with $\mu$FP~\cite{sheeran1984}, a language that utilize functional combinators to describe complex hardware from the composition of small circuits and gates. The Lava family~\cite{bjesse1998, gill2010, york-lava} of functional languages have since expanded upon the ideas of $mu$FP and introduced modern functional features. For instance, Lava exploits monads and type classes to provide multiple interpretations of circuit descriptions, such as simulation, formal verification and generation of netlists, and they use polymorphism and higher order functions to provide general descriptions of hardware designs. No Lava has yet ventured into the design of heterogeneous systems.

Outside of the Lava family, there is C$\lambda$ash~\cite{baaij2010}, a functional hardware description language that is embedded in Haskell. C$\lambda$ash borrows both its syntax and semantics from Haskell to provide a structural design approach that would be familiar to functional programmers, and provides a compiler that is able to produce low-level synthesizable code. Another example is Bluespec~\cite{nikhil2004}, a hardware description language that is influenced by functional languages and includes, for instance, higher-order functions and polymorphism. In contrast to C$\lambda$ash and Lava, Bluespec can describe both software and hardware. Nevertheless, Bluespec descriptions are written at a clock-cycle granularity and therefore provide a lower level of abstraction than most functional languages. A third example is Chisel~\cite{bachrach2012}, a hardware description language embedded in Scala, which, like Bluespec, supports both cycle-accurate software simulation and hardware generation from its descriptions.

Lightweight Modular Staging (LMS) has also been explored as an option to ease the construction of a domain-specific High Level Synthesis (HLS) system~\cite{george2013}. The argument is that LMS eases the reuse of modules between different HLS flows, and makes it easier to link to existing tools, such as the C compilers that are able to produce register-level transfer descriptions. Though the language-specific challenges for LMS are different from those faced by the co-design language, the two approaches are comparable in terms of capability. The way in which code generation of programs is built upon the translation of monads to imperative programs is also reminiscent of Sunroof~\cite{gill2014}, a DSL for generating JavaScript.

Compiling an ordinary C program to a hardware description has great appeal, but finding a translation between the two has however proven to be difficult. Tools like Catapult C~\cite{graphics2008} are able to generate register transfer level code from ordinary C descriptions, but its sequential programs are often a bad fit for the parallelism inherent to most hardware architectures. Additional attempts includes creating dialects of the host language, such as System C~\cite{ghenassia2005}, which restricts its host language to constructs that easier to translate into hardware.

Cryptol~\cite{cryptol} is a DSL for the specification of cryptographic algorithms, and can generate both C and VHDL/Verilog from the same description. While not an embedded language, Cryptol has similar ambitions to the co-design language, in particular the ability to do rapid development and design exploration---although the latest versions of Cryptol no longer support hardware generation. However, since Cryptol is a stand alone language, any extension to it cannot benefit from the ecosystem of tools available in the host language. Another language outside the domain of HLS is Microsoft's Accelerator~\cite{accelerator}, for programming GPUs and various other platforms. Accelerators provides a high-level data-parallel programming model as a library that is available from a conventional imperative programming language like C.

The signal processing language is based on the synchronous data-flow paradigm and is inspired by similar languages from this domain. Of the synchronous languages, Lucid Synchrone~\cite{pouzet2006, colaco2004} is perhaps the biggest source of inspiration and is designed to be used with reactive systems. Initially, the language was introduced as an extension of LUSTRE~\cite{hu1998}, and extended the language with new and powerful features. For instance, automatic clock and type inference were introduced and a limited form of higher-order functions was added. Lucid Synchrone is however a standalone language, and thus cannot be easily integrated the co-design language. Z{\'e}lus~\cite{zelus2013}, a successor of Lucid Synchrone, has shown that synchronous languages can be extended to model hybrid systems as well, that is, system which consist of both continuous and discrete components.

Another, and rather different approach to modeling signal processing is functional reactive programming. Yampa~\cite{yampa2003} is one member of this paradigm, and is used for programming hybrid systems. At its core, functional reactive programming is about describing a system's behaviors and events, where behaviors are continuous and time-varying, reactive values, and events are time-ordered sequences of discrete-time event occurrences~\cite{nilsson2002}. Apart from the different notions of time in synchronous data-flow and functional reactive programming, the idea behind behaviors are quite similar to the signals used in synchronous languages. An event is usually a separate entity, modeling the control flow of a system. Some languages do, however, merge the two concepts at a cost of some elegance by having discrete behaviors, but in return they can describe events in terms of behaviors.

\section{Discussion}
\label{disc}

An embedded systems is a computer system with a dedicated function within a larger system. It is embedded as part of a complete device, and often comes with its own accelerators. When compared to general-purpose computing systems, embedded systems typically provide low power consumption, small size, and low cost. These benefits do however come at the price of limited processing resources, which make them challenging to program: some embedded systems come with real-time computing constraints, for reasons such as safety and usability; others can have low memory constraints, as they are built with the cheapest hardware that meets its performance requirements.

Heterogeneous computing represents an interesting development in the domain of embedded systems, and refers to systems making use of more than one kind of processor or accelerator. The benefit of these heterogeneous systems is not just the combination of several processors, but rather the use of different kinds of processing elements that provide specialized processing capabilities to handle a particular task. As before, this comes at a cost of increased programming complexity, as the level of heterogeneity in a system can introduce non-uniformity in its system development and overall capabilities.

Embedded systems are predominantly developed using low-level, imperative languages and, in the case of most heterogeneous systems, hardware description languages. While low-level languages are good for obtaining maximum performance of system, the provide little or no abstractions and modularity. Developing for such heterogeneous systems with such languages is therefore difficult, as important design choices of, for instance, hardware software partitioning have to be made early, and design exploration in later stages is difficult, as porting programs between hardware and software is often a major undertaking.

The co-design language presented in this thesis are the first steps towards a functional language which can describe the entire design process of a heterogeneous system. The co-design language and its compiler are works in progress, aiming to provide modular, generic and portable description of embedded systems, with a reasonable degree of control over the generated code---programs are designed to have predictable performance and memory usage.

Being embedded in Haskell, the co-design language exploits its host's parametric polymorphism and type classes to support generic program descriptions, facilitating the exploration of good boundary between hardware and software. The co-design language is also designed to be modular in not only the users perspective, but also a language implementers perspective. That is, the language's use of a mixture of shallow and deep embeddings makes it easy to add new features and combinators, as well as instructions, expressions, and interpretations. The vector and signal processing extensions are an example of the former, while section~\ref{instr} gave an example of the latter.

\section{Future Work}
\label{future}

While the co-design language is designed with heterogeneous systems in mind, so far it has only been tested on the Parallella system~\cite{olofsson2014}, which consists of an FPGA with two embedded ARM cores and a many-core accelerator. Furthermore, an implementation of the full AXI4 interconnect should be added to support burst writing of arrays, rather than the single value transmissions offered by the current AXI4-lite implementation.

The process of compiling a hardware program to VHDL, synthesizing a bitstream, and put that onto the FPGA's programmable logic is entirely manual. Also, the physical address of a hardware component has to be manually incorporated into a software program and memory-mapped. These steps should ideally be hidden and automated.

A considerable part of future work for the co-design language are its extensions. The vector and signal processing languages do aid in the design of some systems, but there is still work to be done for fitting programs to many-core devices. For example, only one of the Parallella's embedded ARM cores are currently utilized, and a language of combinators for programming many-core accelerators is still missing. Also, the co-design language could benefit from incorporating a verification back-end to validate properties of a design.

\section{Conclusion}
\label{conc}

Text.

% The co-design library is based on a combination of shallowly and deeply embedded types, which makes the library modular. Furthermore, the software and hardware languages embedded within the library has been made extensible, to support dialects intended for different components. Both languages are also based on the same representation of imperative programs, which is parameterized on the language's instruction set, and their expression and predicate types. So, with the help of this program type, users wishing to define a new imperative language only have to give an implementation of these three types. They get the rest for free.

% Testing of software programs is supported through a variety of interpretation functions, one of which compares the result of running the generated C code with the result of Haskell function---which lets us compare a software program to a model implementation in Haskell. For hardware programs, we currently rely on performing simulation and testing in an external synthesis tool.

% Currently, the co-design library provides two interpretations of its programs: evaluation and compilation. Hardware programs are however often simulated in an external tool to explore a systems response to some combination of inputs, rather than evaluated in Haskell. The final system is intended to support additional interpretations, like simulation. Streaming is also limited in hardware, as the co-design library the only provides an AXI4-lite interconnect for now. Full AXI4 is however something that we wish to implement. Another possible extension would be to provide access to other components of an embedded system, like its multi-core co-processor. We are also interested in exploring a verification or proof framework for the co-design language, where entire designs, or at least properties of them, can be verified.

% Writing the kind of digital signal processing software that is typically used with embedded systems with programs from the co-design language is however still a tedious task. Primarily because of the focus on expressing it algorithms with, relatively low-level, traversals such as for-loops. The vector library addresses this problem, and provides a number of useful abstractions for expressing array computations. Having a functional representation of vectors based on push and pull vectors gives us fusion and control over when and how they are stored in memory. A possible extension for vectors that we want to explore is that of virtual copying, that is, avoiding unnecessary array copies being created when using pully arrays.

% For streaming computations, where inputs arrive one at a time rather than in chunks, the synchronous signal processing provides a convenient front-end for users. The signal library is constructed in a similar fashion as the co-design library, and consists of a deeply embedded core language with a shallow user interface. As such, it retains much of the elegance and modularity of traditional functional programming for signals. Because signals are loosely coupled to the expression type they use, the library does not depend on the co-design language and can be of use to others as well. We intend to further build up the signal library by taking inspiration from related work in synchronous data-flow and introduce clocks as types~\cite{lucy2008}. This would allow the library to deal correctly with (over-)sampling, and to describe multi-clocked networks. Another interesting direction for signal processing could be to investigate other streaming models, such as the one used in Ziria~\cite{ziria2015, fudgets1993}.

\end{document}

%%  LocalWords:  netlists Cryptol DSL LMS implementers
