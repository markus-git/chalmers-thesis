%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%         xeee    
%        d888R    
%       d8888R    
%      @ 8888R    
%    .P  8888R    
%   :F   8888R    
%  x"    8888R    
% d8eeeee88888eer 
%        8888R    
%        8888R    
%     "*%%%%%%**~ 
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[../paper.tex]{subfiles}
\begin{document}

\section{Related Work}
\label{related}

Sheeran pioneered the use of functional languages in hardware design with $\mu$FP~\cite{sheeran1984}, a language that uses functional combinators to describe complex hardware from a set of smaller circuits and gates. The Lava family~\cite{bjesse1998, gill2010, york-lava} of functional languages have since expanded upon the ideas of $mu$FP and introduced modern functional features. For instance, Lava exploits monads and type classes to provide multiple interpretations of circuit descriptions, such as simulation, formal verification and generation of netlists, and they use polymorphism and higher order functions to provide general descriptions of hardware designs. No Lava has yet ventured into the design of heterogeneous systems.

Outside of the Lava family, there is Bluespec~\cite{nikhil2004}, a hardware description language that is influenced by functional languages and includes, for instance, higher-order functions and polymorphism. In contrast to Lava, Bluespec can describe both software and hardware. Nevertheless, Bluespec descriptions are written at a clock-cycle granularity and therefore provide a lower level of abstraction than most functional languages. A third example is Chisel~\cite{bachrach2012}, a hardware description language embedded in Scala, which, like Bluespec, supports both cycle-accurate software simulation and hardware generation from its descriptions.

Compiling an ordinary C program to a hardware description has great appeal, but finding a translation between the two has however proven to be difficult. Tools like Catapult C~\cite{graphics2008} are able to generate register transfer level code from ordinary C descriptions, but its sequential programs are often a bad fit for the parallelism inherent to most hardware architectures. Additional C based attempts includes the creation of SystemC~\cite{ghenassia2005}, a set of classes and macros which provide an even-driven simulation interface in C++. Although strictly a C++ library, SystemC is often viewed as a language of its own that simply reuses C++ syntax. Semantically, it has quite a few similarities to VHDL and Verilog.

Cryptol~\cite{cryptol} is a DSL for the specification of cryptographic algorithms, and can generate both C and VHDL/Verilog from the same description. While not an embedded language, Cryptol has similar ambitions to the co-design language, in particular the ability to do rapid development and design exploration---although the latest versions of Cryptol no longer support hardware generation. However, since Cryptol is a stand alone language, any extension to it cannot benefit from the ecosystem of tools available in the host language. Another language outside the domain of HLS is Microsoft's Accelerator~\cite{accelerator}, for programming GPUs and various other platforms. Accelerators provides a high-level data-parallel programming model as a library that is available from a conventional imperative programming language like C. However, the project seems, unfortunately, to be no longer active.

There exists several methods that aid in the embedding of languages in Haskell. Among these different approaches is finally tagless~\cite{carette2009}, which associates each group of language constructs with a type class, and each interpretation with a semantic domain type. The result is an expressive and compositional way of embedding languages. This does however come at a cost of awkward types---the type of an embedded language is simply a qualified type variable---and it tends to expose implementation details to users. For Scala, the Delite~\cite{arvind2014} library provides a framework of reusable components for embedded languages, like optimizations, and code generators. Delite produces an intermediate representations of user programs that is similar to the model used by the co-design language, but targets a combination of CPU and GPU systems.

Lightweight Modular Staging (LMS) has also been explored as an option to ease the construction of a domain-specific High Level Synthesis (HLS) system~\cite{george2013}. The argument is that LMS eases the reuse of modules between different HLS flows, and makes it easier to link to existing tools, such as the C compilers that are able to produce register transfer level descriptions. Though the language-specific challenges for LMS are different from those faced by the co-design language, the two approaches are comparable in terms of capability. The way in which code generation of programs is built upon the translation of monads to imperative programs is also reminiscent of Sunroof~\cite{gill2014}, a DSL for generating JavaScript.

The extensible types used in the co-design language are built upon Syntactic~\cite{axelsson2012} and Data Types \`{a} La Carte~\cite{DTC}. Syntactic provides a generic model of syntax trees that is extensible and supports generic traversals. Its model is partly derived from Data Types \`{a} La Carte, which defines a composition operator for symbol domains and an interface for symbol subsumption. These techniques can collaborate, and together provide an extensible syntax tree for expressions in the co-design language, as well as the glue for composing instructions.

Among the DSLs embedded in Haskell, Feldspar~\cite{axelsson2010, axelsson2010-2} has perhaps been the biggest source of inspiration for the co-design language. In fact, the co-design language could be considered the spiritual successor of its newer branch called Resource-Aware Feldspar~\cite{raw-feldspar}. Feldspar has many aspects in common with the co-design language, and is designed for programming digital signal processing algorithms, although it does so using vectors rather than signals or streams. Also, the Feldspar compiler is based on similar techniques as those used in the co-design language~\cite{axelsson2016, axelsson2015}. Unlike the co-design language however, Feldspar only targets embedded software elements.

Obsidian~\cite{svensson2008} is an embedded language in Haskell for GPU programming that supports a style of vector programming that is in many ways similar to that of the co-design language. There are however a few differences, as Obsidian is build to specifically target GPUs. For instance, loops are automatically unrolled and it provides a control over the location of data in memory. Which is something that the co-design language currently does not support.

The signal processing language is based on the synchronous data-flow paradigm and is inspired by similar languages from this domain. Of the synchronous languages, Lucid Synchrone~\cite{pouzet2006, colaco2004} is perhaps the biggest source of inspiration and is designed to be used with reactive systems. Initially, the language was introduced as an extension of LUSTRE~\cite{hu1998}, and extended the language with new and powerful features. For instance, automatic clock and type inference were introduced and a limited form of higher-order functions was added. Lucid Synchrone is however a standalone language, and thus cannot be easily integrated with the co-design language. Z{\'e}lus~\cite{zelus2013}, a successor of Lucid Synchrone, has shown that synchronous languages can be extended to model hybrid systems as well, that is, system that consist of both continuous and discrete components.

Another, and rather different approach to modeling signal processing is functional reactive programming. Yampa~\cite{yampa2003} is one member of this paradigm, and is used for programming hybrid systems. At its core, functional reactive programming is about describing a system's behaviors and events, where behaviors are continuous and time-varying, reactive values, and events are time-ordered sequences of discrete-time event occurrences~\cite{nilsson2002}. Apart from the different notions of time in synchronous data-flow and functional reactive programming, the idea behind behaviors are quite similar to the signals used in synchronous languages. An event is usually a separate entity, modeling the control flow of a system. Some languages do, however, merge the two concepts at a cost of some elegance by having discrete behaviors, but in return they can describe events in terms of behaviors.

\section{Discussion}
\label{disc}

% An embedded systems is a computer system with a dedicated function within a larger system. It is embedded as part of a complete device, and often comes with its own accelerators. When compared to general-purpose computing systems, embedded systems typically provide low power consumption, small size, and low cost. These benefits do however come at the price of limited processing resources, which make them challenging to program: some embedded systems come with real-time computing constraints, for reasons such as safety and usability; others can have low memory constraints, as they are built with the cheapest hardware that meets their performance requirements.

Heterogeneous computing represents an interesting development in the domain of embedded systems, and refers to systems making use of more than one kind of processor or accelerator. This comes at a cost of increased programming complexity, as the level of heterogeneity in a system can introduce non-uniformity in its system development and overall capabilities. Embedded systems are predominantly developed using low-level, imperative languages and, in the case of most heterogeneous systems, hardware description languages. While low-level languages are good for obtaining maximum performance of system, they provide little or no abstractions or modularity. 

The co-design language presented in this thesis are the first steps towards a functional language which can describe the entire design process of a heterogeneous system. Both the co-design language and its compiler are works in progress, aiming to provide modular, generic and portable description of embedded systems, with a reasonable degree of control over the generated code---programs are designed to have predictable performance and memory usage. That is, the co-design language is based on a design where memory usage is explicitly managed by the user, leading to a lower and easier to predict memory usage than that of a typical lazy language.

Being embedded in Haskell, the co-design language exploits its host's parametric polymorphism and type classes to support generic program descriptions, facilitating the exploration of good boundary between hardware and software. That is, the co-design library provides a type for software programs, hardware programs, and a kind of generic programs that are constrained by the operations it requires rather than the entire software or hardware languages. Once a satisfactory hardware software partitioning has been found, these generic programs can be turned into language specific programs by simply changing their type, after which the program can be tailored to its target if necessary. The boundary between software and hardware is itself fully implemented in the co-design language, and provided as a function that, given an encoding of a program's type signature, generates a custom AXI4-lite interconnect.

The co-design language is also designed to be modular in not only the user's perspective, but also a language implementers perspective. That is, the language's use of a mixture of shallow and deep embeddings makes it easy to add new features and combinators, as well as instructions, expressions, and interpretations. The vector and signal processing extensions are an example of the former, while section~\ref{instr} gave an example of the latter. Extensions of instructions and expressions are safe in the sense that they can be defined separately from the type they extend, and any interpretation the original types may have supported can be regained for the extended type by adding support for its new extension.

\section{Future Work}
\label{future}

While the co-design language is designed with heterogeneous systems in mind, so far it has only been tested on the Parallella system~\cite{olofsson2014}, which consists of an FPGA with two embedded ARM cores and a many-core accelerator. Of the four processing elements on the Parallella, only the FPGA and a single ARM core is so far used. There has been earlier attempts at describing the many-core accelerator as well, but they have yet been included in the latest version of the co-design language. The accelerator is programmed in C, but the compiler must then also consider the location of sub programs on the different small processors. Furthermore, an implementation of the full AXI4 interconnect should be added to support burst writing of arrays, rather than the single value transmissions offered by the current AXI4-lite implementation.

The process of compiling a hardware program to VHDL, synthesizing a bitstream, and put that onto the FPGA's programmable logic is entirely manual, as shown in Appendix~\ref{vivado}. Most synthesizers do however support a scripting language that could be used to automate the process. Also, the physical address of a hardware component has to be manually incorporated into a software program and memory-mapped. These steps should ideally be hidden and automated, where the hardware compiler automatically feeds the software compiler with addresses it got from the synthesizer.

A considerable part of future work for the co-design language are its extensions. The vector and signal processing languages do aid in the design of some systems, but there is still work to be done for fitting programs to many-core devices. For example, only one of the Parallella's embedded ARM cores are currently used, and a language of combinators for programming many-core accelerators is still missing. Also, the co-design language could benefit from incorporating a verification back-end to validate its generated designs, and effort has already been put into using a SMT solver to verify assertions produced by the co-design language's compiler. Another interesting extension of the co-design language is the introduction of a new signal processing framework like Ziria~\cite{ziria2015}, but embedded in Haskell.

\section{Conclusion}
\label{conc}

% The hardware software co-design language is currently focused on describing software and hardware systems through C and VHDL, and includes operations for most standard instructions in both languages. Both the hardware and software side of the co-design language are however extensible to support the addition of new operations. The co-design language is also extensible from a user's perspective, which facilitates the addition of new features and tools.

The co-design project originally set out to see how far Haskell and embedded languages would go towards the design of a heterogeneous embedded system, where at least two sub languages were required to describe the system's various processing elements. So far, the functional approach to co-design has proved useful.

A hardware software co-design language has been defined, capable of generating C for software elements, VHDL for hardware elements, and a mixture of the two for orchestrating the communication between software and hardware elements. The co-design language is also able to describe generic programs, a feature that is quite useful as it facilitates design exploration.

The vector and signal processing extensions introduced a compositional style for computations in their respective domains. Both extensions enabled, for instance, a FIR filter to be implemented using only a single line of code while precisely capturing its mathematical specification. Their high-level combinators is welcome reprieve form the typically low-level programming of embedded systems, while features such as fusion ensures performance does not suffer. While both extensions were intended to be used with the co-design language, they abstract over their underlying expression types and can be used with other languages that provide pure expressions.

A common model of imperative programs for both the software and hardware languages proved to be quite useful, as it enabled many of its interesting interpretation techniques to be reused for the two languages. Furthermore, as the model was designed to be loosely coupled with the program's associated types, the model is useful for language development outside of hardware software co-design. The current approach to compilation as a typed translation between progressively smaller languages has helped safeguard against most of the issues typically associated with untyped compilation schemes.

% Vectors provide a number of useful combinators for expressing array computations, and their functional representation based on push and pull arrays means vectors can be combined efficiently. For streaming computations, signals provides a set of combinators based on synchronous data-flow that assigns a notion of time to computations.

% As software and hardware was based on  of imperative 

% A common representation of imperative programs is for both software and hardware programs, that is parameterized by the languages' instruction sets, expressions, and predicate types, have turned out to be quite useful. Furthermore, due to the loose coupling between programs and their associated types, other languages can reuse programs and only provide their own instructions and expressions.

% Also, compilation is expressed as a typed translation between progressively smaller languages, safeguarding against errors typically found in untyped translations.

\end{document}

%%  LocalWords:  netlists Cryptol DSL LMS implementers
